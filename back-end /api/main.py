import os
 
# ØªØ­Ø¯ÙŠØ¯ Ù…Ø¬Ù„Ø¯ Ù„Ù„ÙƒØ§Ø´ Ø¯Ø§Ø®Ù„ Docker
os.environ['TRANSFORMERS_CACHE'] = '/tmp/huggingface_cache'
os.environ['HF_HOME'] = '/tmp/huggingface'
 
from flask import Flask, request, jsonify
from sentence_transformers import SentenceTransformer
from pinecone import Pinecone
import google.generativeai as genai
from langdetect import detect

# Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„ØªØ­ÙŠØ§Øª
greetings_dict = {
    "Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…": "ÙˆØ¹Ù„ÙŠÙƒÙ… Ø§Ù„Ø³Ù„Ø§Ù…",
    "ØµØ¨Ø§Ø­ Ø§Ù„Ø®ÙŠØ±": "ØµØ¨Ø§Ø­ Ø§Ù„Ù†ÙˆØ±",
    "Ù…Ø³Ø§Ø¡ Ø§Ù„Ø®ÙŠØ±": "Ù…Ø³Ø§Ø¡ Ø§Ù„Ù†ÙˆØ±",
    "Ø£Ù‡Ù„Ø§": "Ø£Ù‡Ù„Ø§ Ø¨ÙŠÙƒ",
    "Ø£Ù‡Ù„Ø§Ù‹": "Ø£Ù‡Ù„Ø§Ù‹ ÙˆØ³Ù‡Ù„Ø§Ù‹",
    "Ù‡Ø§ÙŠ": "Ù‡Ø§ÙŠ",
    "Ù‡Ù„Ø§": "Ù‡Ù„Ø§ ÙÙŠÙƒ",
    "hello": "hello!",
    "hi": "hi!",
    "hey": "hey there!",
    "Ø§Ø²ÙŠÙƒ": "Ø§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡ØŒ Ø§Ù†Øª Ø¹Ø§Ù…Ù„ Ø§ÙŠÙ‡ØŸ",
    "Ø§Ø²ÙŠÙƒØŸ": "Ø§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡ØŒ Ø§Ù†Øª Ø¹Ø§Ù…Ù„ Ø§ÙŠÙ‡ØŸ"
}

def check_greeting(question):
    for greeting in greetings_dict:
        if greeting.lower() in question.lower():
            return greetings_dict[greeting]
    return None
 
# ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª
embedding_model = SentenceTransformer("intfloat/multilingual-e5-large")
 
pc = Pinecone(api_key="#")
index = pc.Index("newindex")
 
genai.configure(api_key="#")
model = genai.GenerativeModel("gemini-2.0-flash")
 
app = Flask(__name__)
chat_history = []
 
def detect_language(text):
    try:
        return detect(text)
    except:
        return "unknown"
 
def get_answer_from_pinecone(user_question, embedding_model, index, top_k=5, similarity_threshold=0.7):
    try:
        question_vector = embedding_model.encode(user_question).tolist()
    except Exception as e:
        return [f"âŒ Error embedding question: {e}"]
 
    try:
        search_result = index.query(
            vector=question_vector,
            top_k=top_k,
            include_metadata=True
        )
    except Exception as e:
        return [f"âŒ Error querying Pinecone: {e}"]
 
    matches = [m for m in search_result.matches if m.score >= similarity_threshold]
    sorted_matches = sorted(matches, key=lambda x: x.score, reverse=True)
 
    answers = []
    for m in sorted_matches:
        answer = m.metadata.get('answer', '').strip()
        source = m.metadata.get('source', 'unknown')
        score = round(m.score, 3)
        if answer:
            answers.append(f"â€¢ ({score}) from [{source}]:\n{answer}")
    return answers if answers else ["âš ï¸ No similar answers found."]
 
def ask_gemini_with_combined_answer(user_question, pinecone_answers=[], history=[]):
    context = "\n".join([f"ğŸ‘¤ {q}\nğŸ¤– {a}" for q, a in history])
    extracted_info = "\n".join([f"â€¢ {ans}" for ans in pinecone_answers]) if pinecone_answers else "None"
    lang = detect_language(user_question)
 
    if lang == "ar":
        
        instructions = """
â— Ù‡Ø§Ù…: Ø§Ø³ØªØ®Ø¯Ù… ÙÙ‚Ø· Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.
ğŸ“œ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©:
{context}
ğŸ‘¤ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙŠØ³Ø£Ù„: {user_question}
ğŸ“š Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:
{extracted_info}
ğŸ“Œ Ø§Ù„Ø±Ø¯:
"""
    else:
        
        instructions = """
â— Important: Use only database information.
ğŸ“œ Previous conversation:
{context}
ğŸ‘¤ User asks: {user_question}
ğŸ“š Retrieved info:
{extracted_info}
ğŸ“Œ Response:
"""
 
    prompt = instructions.format(
        context=context or ("Ù„Ø§ ÙŠÙˆØ¬Ø¯" if lang == "ar" else "None"),
        user_question=user_question,
        extracted_info=extracted_info
    )
    response = model.generate_content(prompt)
    return response.text.strip()
 
@app.route("/ask", methods=["POST"])
def ask():
    data = request.json
    question = data.get("question")
    if not question:
        return jsonify({"error": "Missing question"}), 400

    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØ­ÙŠØ§Øª
    greeting_response = check_greeting(question)
    if greeting_response:
        return jsonify({"answer": greeting_response})

    pinecone_answer = get_answer_from_pinecone(question, embedding_model, index)
    final_answer = ask_gemini_with_combined_answer(question, pinecone_answer, chat_history)
    chat_history.append((question, final_answer))
    return jsonify({
        "answer": final_answer
    })
 
@app.route("/")
def home():
    return "ğŸ¤– API is running. Use POST /ask with {'question': '...'}"
 
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=7860)
